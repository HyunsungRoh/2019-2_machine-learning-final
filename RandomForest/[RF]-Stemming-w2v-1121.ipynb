{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data Loading\n",
    "\n",
    "프로젝트 폴더에서 데이터를 불러온다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "\n",
    "dataOutPath='./data_out/'\n",
    "File = 'train_all.csv'\n",
    "#testFile = 'FDOT-clean.csv'\n",
    "\n",
    "Input = pd.read_csv(dataOutPath+File)\n",
    "#testInput = pd.read_csv(dataOutPath+testFile)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Input['clauses'][:414]\n",
    "test_label = Input['label'][:414]\n",
    "\n",
    "train_data = Input['clauses'][415:]\n",
    "train_label = Input['label'][415:]\n",
    "\n",
    "train_data_df = pd.DataFrame(data = {\"clauses\": train_data, \"label\":train_label})\n",
    "train_data_df.to_csv(dataOutPath+'train_data.csv')\n",
    "\n",
    "test_data_df = pd.DataFrame(data = {\"clauses\": test_data, \"label\":test_label})\n",
    "test_data_df.to_csv(dataOutPath+'test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for clause in train_data:\n",
    "    sentences.append(clause.split())\n",
    "\n",
    "test_sent=[]\n",
    "for clause in test_data:\n",
    "    test_sent.append(clause.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### word2Vec - vectorizing hyperparameter\n",
    "\n",
    "- num_features: 각 단어에 대해 임베딩된 벡터의 차원 \n",
    "- min_word_count: 적은 빈도수의 단어는 제거하기위한 최소 단어 수 \n",
    "- num_workers: 학습 프로세스 수 \n",
    "- context: 워드투벡 수행시 컨텍스트 위도우 크기 지정 \n",
    "- downsampling: 다운샘플링 비율 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2Vec - vectorizing hyperparameter \n",
    "\n",
    "num_features = 1000\n",
    "min_word_count=10\n",
    "num_workers=4\n",
    "context=2\n",
    "downsampling=1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level= logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 23:33:25,931 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2019-11-26 23:33:25,955 : INFO : collecting all words and their counts\n",
      "2019-11-26 23:33:25,956 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-26 23:33:25,967 : INFO : collected 2139 word types from a corpus of 24305 raw words and 1659 sentences\n",
      "2019-11-26 23:33:25,968 : INFO : Loading a fresh vocabulary\n",
      "2019-11-26 23:33:25,974 : INFO : effective_min_count=10 retains 507 unique words (23% of original 2139, drops 1632)\n",
      "2019-11-26 23:33:25,976 : INFO : effective_min_count=10 leaves 19700 word corpus (81% of original 24305, drops 4605)\n",
      "2019-11-26 23:33:25,983 : INFO : deleting the raw counts dictionary of 2139 items\n",
      "2019-11-26 23:33:25,986 : INFO : sample=0.001 downsamples 93 most-common words\n",
      "2019-11-26 23:33:25,987 : INFO : downsampling leaves estimated 14896 word corpus (75.6% of prior 19700)\n",
      "2019-11-26 23:33:25,992 : INFO : estimated required memory for 507 words and 1000 dimensions: 4309500 bytes\n",
      "2019-11-26 23:33:25,993 : INFO : resetting layer weights\n",
      "2019-11-26 23:33:26,027 : INFO : training model with 4 workers on 507 vocabulary and 1000 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n",
      "2019-11-26 23:33:26,041 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-26 23:33:26,080 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-26 23:33:26,116 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-26 23:33:26,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-26 23:33:26,126 : INFO : EPOCH - 1 : training on 24305 raw words (14790 effective words) took 0.1s, 160249 effective words/s\n",
      "2019-11-26 23:33:26,147 : INFO : worker thread finished; awaiting finish of 3 more threads"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-11-26 23:33:26,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-26 23:33:26,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-26 23:33:26,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-26 23:33:26,224 : INFO : EPOCH - 2 : training on 24305 raw words (14897 effective words) took 0.1s, 172167 effective words/s\n",
      "2019-11-26 23:33:26,235 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-26 23:33:26,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-26 23:33:26,308 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-26 23:33:26,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-26 23:33:26,313 : INFO : EPOCH - 3 : training on 24305 raw words (14908 effective words) took 0.1s, 178596 effective words/s\n",
      "2019-11-26 23:33:26,326 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-26 23:33:26,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-26 23:33:26,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-26 23:33:26,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-26 23:33:26,406 : INFO : EPOCH - 4 : training on 24305 raw words (14933 effective words) took 0.1s, 177688 effective words/s\n",
      "2019-11-26 23:33:26,428 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-26 23:33:26,467 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-26 23:33:26,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-26 23:33:26,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-26 23:33:26,504 : INFO : EPOCH - 5 : training on 24305 raw words (14949 effective words) took 0.1s, 170729 effective words/s\n",
      "2019-11-26 23:33:26,505 : INFO : training on a 121525 raw words (74477 effective words) took 0.5s, 156104 effective words/s\n",
      "2019-11-26 23:33:26,506 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"training model...\")\n",
    "model = word2vec.Word2Vec(sentences, \n",
    "                          workers=num_workers, \n",
    "                          size= num_features, \n",
    "                          min_count=min_word_count, \n",
    "                          window= context, \n",
    "                          sg=1,\n",
    "                          sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 23:33:40,764 : INFO : saving Word2Vec object under ./data_out/wvModels/1126-train-wvModel, separately None\n",
      "2019-11-26 23:33:40,766 : INFO : not storing attribute vectors_norm\n",
      "2019-11-26 23:33:40,767 : INFO : not storing attribute cum_table\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-11-26 23:33:40,836 : INFO : saved ./data_out/wvModels/1126-train-wvModel\n"
     ]
    }
   ],
   "source": [
    "dataOutPath='./data_out/wvModels/'\n",
    "model_name = '1126-train-wvModel'\n",
    "model.save(dataOutPath+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x18c7488aa90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(clauses, model, num_features):\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in clauses:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords +1.\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_feature_vec(sentences, model, num_features):\n",
    "    \n",
    "    clauses_feature_vecs = np.zeros((len(sentences), num_features), dtype='float32')\n",
    "    \n",
    "    for i, clauses in enumerate(sentences):\n",
    "        clauses_feature_vecs[i] = make_feature_vec(clauses, model, num_features)\n",
    "    \n",
    "    return clauses_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "training_vec = get_avg_feature_vec(sentences, model,num_features)\n",
    "test_vec = get_avg_feature_vec(test_sent,model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8672199e-03, -2.0716395e-04,  8.1261940e-02, ...,\n",
       "         2.1132234e-02, -1.1783892e-02, -3.0656539e-02],\n",
       "       [-1.8930067e-03, -1.4160702e-04,  7.8604855e-02, ...,\n",
       "         2.0613899e-02, -1.1495780e-02, -2.9127987e-02],\n",
       "       [-1.7806385e-03, -6.4423139e-04,  8.0798224e-02, ...,\n",
       "         2.0886796e-02, -1.1806290e-02, -3.0085692e-02],\n",
       "       ...,\n",
       "       [-1.4902474e-03,  5.9511065e-05,  8.0915585e-02, ...,\n",
       "         2.1244293e-02, -1.2060645e-02, -3.0674154e-02],\n",
       "       [-1.7335260e-03, -6.0064491e-04,  7.6889098e-02, ...,\n",
       "         1.9991465e-02, -1.1061103e-02, -2.9178079e-02],\n",
       "       [-1.6983390e-03, -3.5128242e-04,  7.3053911e-02, ...,\n",
       "         1.9096652e-02, -1.0670877e-02, -2.7415082e-02]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 훈련데이터와 검증데이터 나누기\n",
    "\n",
    "전체 훈련데이터를  t_size 비율만큼 훈련:검증 데이터로 나눈다. \n",
    "sklearn의 train_test_split 함수를 사용해서 자동으로 분할한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1327, 1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "t_size=0.2 \n",
    "r_seed=23\n",
    "\n",
    "train_cl, eval_cl, train_lb, eval_lb = train_test_split(training_vec, train_label, test_size=t_size, random_state=r_seed )\n",
    "\n",
    "train_cl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 랜덤포레스트 분류\n",
    "\n",
    "- RandomForestClassifier 는 sklearn의 ensemble  라이브러리에서 제공한다. \n",
    "- forest라는 이름으로 분류기 객체를 생성하고, n_estimators 변수로 결정트리의 개수를 지정한다. \n",
    "- forest.fit 함수의 인자로 훈련 데이터와 레이블을 주입한다. \n",
    "- 검증데이터셋 (eval_cl, eval_lb)로 분류정확도를 측정한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "forest.fit(train_cl, train_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training: 1.000000\n",
      "Accuracy: 0.698795\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of training: %f\" % forest.score(train_cl, train_lb))\n",
    "print(\"Accuracy: %f\" % forest.score(eval_cl, eval_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 분류결과 \n",
    "- n_estimators =n 일때, n 값이 커질수록 정확도가 향상됨을 알 수 있다. \n",
    "- n=100 일때 accuracy = 95% 달성 \n",
    "\n",
    "- lema 보다 stemming 했을때 더 정확도가 높게 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70,  56],\n",
       "       [ 44, 162]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = forest.predict(eval_cl)\n",
    "cm = confusion_matrix(eval_lb, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69,0.5,'Truth')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot = True)\n",
    "plt.xlabel('Predected')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# 테스트 데이터 파일에 쓰기 -\n",
    "\n",
    "output_PATH='./data_out/results/'\n",
    "\n",
    "if not os.path.exists(output_PATH):\n",
    "    os.makedirs(output_PATH)\n",
    "    \n",
    "# 위에서 만든 랜덤 포레스트 분류기를 통해 예측값을 가져온다.\n",
    "result = forest.predict(test_vec)\n",
    "\n",
    "# 판다스 데이터 프레임을 통해 데이터를 구성해서 output에 넣는다.\n",
    "output = pd.DataFrame( data={\"label\": test_label ,  \"predict\": result} )\n",
    "\n",
    "# 이제 csv파일로 만든다.\n",
    "output.to_csv(output_PATH + \"w2v-predict-test.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
