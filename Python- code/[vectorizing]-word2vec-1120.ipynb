{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Word2Vec- vectorizing- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "PATH = './data_out/'\n",
    "CSV = 'train_clean.csv'\n",
    "\n",
    "train_data = pd.read_csv(PATH+CSV)\n",
    "\n",
    "clauses = list(train_data['clauses'])\n",
    "label = list(train_data['label'])\n",
    "\n",
    "sentences =[]\n",
    "for clause in clauses:\n",
    "    sentences.append(clause.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2Vec - vectorizing hyperparameter**\n",
    "\n",
    "- num_features: 각 단어에 대해 임베딩된 벡터의 차원 \n",
    "- min_word_count: 적은 빈도수의 단어는 제거하기위한 최소 단어 수 \n",
    "- num_workers: 학습 프로세스 수 \n",
    "- context: 워드투벡 수행시 컨텍스트 위도우 크기 지정 \n",
    "- downsampling: 다운샘플링 비율 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2Vec - vectorizing hyperparameter \n",
    "\n",
    "num_features = 300\n",
    "min_word_count=10\n",
    "num_workers=4\n",
    "context=10\n",
    "downsampling=1e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level= logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 11:00:42,937 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2019-11-20 11:00:42,966 : INFO : collecting all words and their counts\n",
      "2019-11-20 11:00:42,967 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 11:00:43,027 : INFO : collected 4156 word types from a corpus of 91123 raw words and 4049 sentences\n",
      "2019-11-20 11:00:43,029 : INFO : Loading a fresh vocabulary\n",
      "2019-11-20 11:00:43,039 : INFO : effective_min_count=10 retains 1328 unique words (31% of original 4156, drops 2828)\n",
      "2019-11-20 11:00:43,040 : INFO : effective_min_count=10 leaves 83120 word corpus (91% of original 91123, drops 8003)\n",
      "2019-11-20 11:00:43,068 : INFO : deleting the raw counts dictionary of 4156 items\n",
      "2019-11-20 11:00:43,070 : INFO : sample=0.001 downsamples 70 most-common words\n",
      "2019-11-20 11:00:43,071 : INFO : downsampling leaves estimated 73043 word corpus (87.9% of prior 83120)\n",
      "2019-11-20 11:00:43,078 : INFO : estimated required memory for 1328 words and 300 dimensions: 3851200 bytes\n",
      "2019-11-20 11:00:43,080 : INFO : resetting layer weights\n",
      "2019-11-20 11:00:43,128 : INFO : training model with 4 workers on 1328 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 11:00:43,223 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 11:00:43,229 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 11:00:43,239 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 11:00:43,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 11:00:43,246 : INFO : EPOCH - 1 : training on 91123 raw words (72994 effective words) took 0.1s, 702822 effective words/s\n",
      "2019-11-20 11:00:43,344 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 11:00:43,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 11:00:43,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 11:00:43,366 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 11:00:43,367 : INFO : EPOCH - 2 : training on 91123 raw words (73046 effective words) took 0.1s, 676167 effective words/s\n",
      "2019-11-20 11:00:43,460 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 11:00:43,462 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 11:00:43,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 11:00:43,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 11:00:43,483 : INFO : EPOCH - 3 : training on 91123 raw words (73086 effective words) took 0.1s, 681326 effective words/s\n",
      "2019-11-20 11:00:43,575 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 11:00:43,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 11:00:43,575 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 11:00:43,602 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 11:00:43,603 : INFO : EPOCH - 4 : training on 91123 raw words (73004 effective words) took 0.1s, 688220 effective words/s\n",
      "2019-11-20 11:00:43,690 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 11:00:43,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 11:00:43,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 11:00:43,718 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 11:00:43,719 : INFO : EPOCH - 5 : training on 91123 raw words (72982 effective words) took 0.1s, 676359 effective words/s\n",
      "2019-11-20 11:00:43,720 : INFO : training on a 455615 raw words (365112 effective words) took 0.6s, 617827 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"training model...\")\n",
    "model = word2vec.Word2Vec(sentences, \n",
    "                          workers=num_workers, \n",
    "                          size= num_features, \n",
    "                          min_count=min_word_count, \n",
    "                          window= context, \n",
    "                          sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 11:02:29,580 : INFO : saving Word2Vec object under ./data_out/1120-word2vec_model, separately None\n",
      "2019-11-20 11:02:29,581 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 11:02:29,583 : INFO : not storing attribute cum_table\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-11-20 11:02:29,631 : INFO : saved ./data_out/1120-word2vec_model\n"
     ]
    }
   ],
   "source": [
    "dataOutPath='./data_out/'\n",
    "model_name = '1120-word2vec_model'\n",
    "model.save(dataOutPath+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
